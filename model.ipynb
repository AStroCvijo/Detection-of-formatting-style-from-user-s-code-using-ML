{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1ea084-d57c-4e18-abe1-f035daf9fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, AdamW\n",
    "from transformers import BertModel, BertConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88ec0f0-f77b-4f68-8485-6c4dc29d552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Dataset Class\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            # Read and split the data into tokens\n",
    "            self.data = f.read().split(' ')\n",
    "        \n",
    "        # Create input-output pairs\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for i in range(len(self.data) - 1):\n",
    "            self.inputs.append(self.data[i])\n",
    "            # Define the label: 0 for space, 1 for newline, 2 for other\n",
    "            if self.data[i + 1] == \"<space>\":\n",
    "                self.labels.append(0)  # Space\n",
    "            elif self.data[i + 1] == \"<newline>\":\n",
    "                self.labels.append(1)  # Newline\n",
    "            else:\n",
    "                self.labels.append(2)  # Other\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db58b710-c8a2-44e4-b4d4-a1a2648df00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 77431\n",
      "Batch size: 32\n",
      "Number of batches: 2420\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'data/preprocessed_cpp_data.txt'  # Update this with your actual file path\n",
    "dataset = TokenDataset(file_path)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32  # or your defined batch size\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Get and print dataset and DataLoader size\n",
    "dataset_size = len(dataset)\n",
    "num_batches = (dataset_size + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"Total dataset size: {dataset_size}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of batches: {num_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33880101-a258-48ab-8a8c-3b443f0c9e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/', '/', '<space>', 'Copyright', '<space>', '(', 'c', ')', '<space>', '2011', '<space>', 'The', '<space>', 'LevelDB', '<space>', 'Authors', '.', '<space>', 'All', '<space>', 'rights', '<space>', 'reserved', '.', '<newline>', '/', '/', '<space>', 'Use', '<space>', 'of', '<space>')\n",
      "tensor([2, 0, 2, 0, 2, 2, 2, 0, 2, 0, 2, 0, 2, 0, 2, 2, 0, 2, 0, 2, 0, 2, 2, 1,\n",
      "        2, 2, 0, 2, 0, 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    print(inputs)\n",
    "    print(labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7cc1cfe-25ec-4085-a6d1-2a07fca30c05",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39msize)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "print(dataloader.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40437876-e089-415e-b146-8c4c04fda727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define a BERT Model from Scratch\n",
    "class BertForSequenceClassification(nn.Module):\n",
    "    def __init__(self, num_labels=3):\n",
    "        super(BertForSequenceClassification, self).__init__()\n",
    "        # Define the BERT configuration\n",
    "        self.config = BertConfig(\n",
    "            vocab_size=30522,  # This is the vocabulary size for BERT\n",
    "            hidden_size=768,  # The size of the hidden layers\n",
    "            num_hidden_layers=12,  # Number of transformer blocks\n",
    "            num_attention_heads=12,  # Number of attention heads\n",
    "            intermediate_size=3072,  # Size of the feed-forward layer\n",
    "            hidden_act='gelu',  # Activation function\n",
    "            num_labels=num_labels  # Number of labels for classification\n",
    "        )\n",
    "        # Define BERT model\n",
    "        self.bert = BertModel(self.config)\n",
    "        # Define classification head\n",
    "        self.classifier = nn.Linear(self.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  # Get the pooled output\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a17e35-c22c-4a3e-bb99-7a634c8892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Set Device and Initialize Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertForSequenceClassification(num_labels=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e379bc33-d8e5-44b7-886d-5f60ab72c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define Tokenizer and Optimizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')  # Use a pre-trained tokenizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8cf35fc-caa6-4f80-a77d-b13f0d1594df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/2420 [00:00<?, ?it/s]C:\\Users\\JovanAStro\\AppData\\Local\\Temp\\ipykernel_3120\\4221759339.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels).long().clone().detach().to(device)\n",
      "  0%|                                                                               | 1/2420 [00:02<1:40:13,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [1/2420], Loss: 0.9389889240264893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 2/2420 [00:05<1:50:26,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [2/2420], Loss: 0.8532786965370178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 3/2420 [00:08<2:02:19,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [3/2420], Loss: 0.826081395149231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 4/2420 [00:12<2:11:26,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [4/2420], Loss: 0.9342685341835022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 5/2420 [00:14<1:58:17,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [5/2420], Loss: 0.9509748220443726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 6/2420 [00:19<2:21:54,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [6/2420], Loss: 0.8352755308151245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                              | 7/2420 [00:21<2:06:29,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [7/2420], Loss: 0.8714090585708618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                              | 8/2420 [00:24<1:56:49,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [8/2420], Loss: 0.8526116013526917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                              | 9/2420 [00:26<1:50:13,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [9/2420], Loss: 0.8827657699584961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                             | 10/2420 [00:28<1:45:30,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [10/2420], Loss: 0.6861468553543091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                             | 11/2420 [00:32<1:54:56,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [11/2420], Loss: 0.7749091982841492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                             | 12/2420 [00:34<1:49:20,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [12/2420], Loss: 0.7767430543899536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                             | 13/2420 [00:38<1:58:06,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [13/2420], Loss: 0.848986029624939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                             | 14/2420 [00:43<2:32:34,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [14/2420], Loss: 0.9186177849769592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▍                                                                             | 15/2420 [00:47<2:30:57,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [15/2420], Loss: 0.7950199842453003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 16/2420 [00:50<2:14:23,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [16/2420], Loss: 0.8984153270721436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 17/2420 [00:52<2:05:42,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [17/2420], Loss: 0.7576972246170044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 18/2420 [00:55<2:03:32,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [18/2420], Loss: 0.6971703171730042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                             | 19/2420 [00:59<2:17:42,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [19/2420], Loss: 0.8344874978065491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                             | 20/2420 [01:02<2:05:33,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [20/2420], Loss: 0.5822280049324036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                             | 21/2420 [01:05<2:06:08,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [21/2420], Loss: 0.9260549545288086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                             | 22/2420 [01:08<2:06:38,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [22/2420], Loss: 0.8770410418510437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                             | 23/2420 [01:11<2:04:12,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [23/2420], Loss: 0.9328681230545044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 24/2420 [01:14<1:59:16,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [24/2420], Loss: 0.841187059879303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 25/2420 [01:16<1:52:14,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [25/2420], Loss: 0.8797575831413269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 26/2420 [01:19<1:47:51,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [26/2420], Loss: 0.6839094758033752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                             | 27/2420 [01:22<1:57:37,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [27/2420], Loss: 0.8098555207252502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 28/2420 [01:27<2:13:43,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [28/2420], Loss: 0.6848344802856445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 29/2420 [01:31<2:31:22,  3.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [29/2420], Loss: 0.9493051767349243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 30/2420 [01:35<2:27:49,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [30/2420], Loss: 0.7273212671279907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 31/2420 [01:39<2:30:16,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [31/2420], Loss: 0.8027989864349365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                             | 31/2420 [01:41<2:10:02,  3.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Print the loss for the current mini-batch\u001b[39;00m\n",
      "File \u001b[1;32mF:\\Programming_Stuff\\Anaconda\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mF:\\Programming_Stuff\\Anaconda\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mF:\\Programming_Stuff\\Anaconda\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 6: Training Loop\n",
    "epochs = 3\n",
    "model.train()  # Set the model to training mode\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (inputs, labels) in enumerate(tqdm(dataloader)):\n",
    "        # Tokenize the inputs\n",
    "        inputs = tokenizer(inputs, padding=True, truncation=True, return_tensors='pt', max_length=128).to(device)\n",
    "\n",
    "        # Convert labels to tensor correctly\n",
    "        labels = torch.tensor(labels).long().clone().detach().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss for the current mini-batch\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Batch [{batch_idx + 1}/{len(dataloader)}], Loss: {loss.item()}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5004f-757d-4b46-9e1d-fec15770091e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
